{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign depots\n",
    "This notebook assigns depots to parcels per operator by selecting for each parcel the depot that is the closest in routed distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manage inputs and outputs\n",
    "graph_path = \"../../results/network/accessible.graphml\"\n",
    "depots_path = \"../../results/depots/per_operator/dhl.gpkg\"\n",
    "parcels_path = \"../../results/parcels/per_operator/baseline_2022/dhl.gpkg\"\n",
    "output_path = \"../../results/parcels/depots/baseline_2022/dhl.gpkg\"\n",
    "\n",
    "if \"snakemake\" in locals():\n",
    "    graph_path = snakemake.input[\"graph\"]\n",
    "    depots_path = snakemake.input[\"depots\"]\n",
    "    parcels_path = snakemake.input[\"parcels\"]\n",
    "    output_path = snakemake.output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network\n",
    "graph = ox.load_graphml(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load depots\n",
    "df_depots = gpd.read_file(depots_path)\n",
    "df_depots = df_depots.rename(columns = { \"node\": \"depot_node\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load parcels\n",
    "df_parcels = gpd.read_file(parcels_path)\n",
    "df_parcels = df_parcels.rename(columns = { \"node\": \"parcel_node\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(df_depots[\"operator\"].unique())) == 1\n",
    "assert len(set(df_parcels[\"operator\"].unique())) == 1\n",
    "assert df_depots[\"operator\"].unique()[0] == df_parcels[\"operator\"].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract individual nodes\n",
    "depot_nodes = set(df_depots[\"depot_node\"].unique())\n",
    "parcel_nodes = set(df_parcels[\"parcel_node\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate distances (coudl be parallelized))\n",
    "df_distances = { \"depot_node\": [], \"parcel_node\": [], \"distance\": [] }\n",
    "edge_lengths = nx.get_edge_attributes(graph, \"length\")\n",
    "\n",
    "for depot_node in tqdm(depot_nodes):\n",
    "    routes = nx.single_source_dijkstra_path(graph, depot_node, weight = \"length\")\n",
    "\n",
    "    for parcel_node in parcel_nodes:\n",
    "        route = routes[parcel_node]\n",
    "    \n",
    "        df_distances[\"depot_node\"].append(depot_node)\n",
    "        df_distances[\"parcel_node\"].append(parcel_node)\n",
    "\n",
    "        df_distances[\"distance\"].append(sum([\n",
    "            edge_lengths[(u, v, 0)]\n",
    "            for u, v in zip(route[0:-1], route[1:])\n",
    "        ]))\n",
    "\n",
    "df_distances = pd.DataFrame(df_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_distances = df_distances.sort_values(by = \"distance\")\n",
    "df_distances = df_distances.drop_duplicates(\"parcel_node\", keep = \"first\")\n",
    "df_distances = df_distances.drop_duplicates([\"parcel_node\", \"depot_node\"], keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge, sort, and drop duplicates to find closest assignments\n",
    "df_assignment = pd.merge(df_parcels[[\"parcel_id\", \"parcel_node\"]], df_distances[[\n",
    "    \"parcel_node\", \"depot_node\"]], on = \"parcel_node\")\n",
    "\n",
    "df_assignment = pd.merge(df_assignment, df_depots[[\n",
    "    \"depot_id\", \"depot_node\"]], on = \"depot_node\")\n",
    "\n",
    "df_assignment = df_assignment.sort_values(by = [\"parcel_id\", \"depot_id\"])\n",
    "df_assignment = df_assignment.drop_duplicates(\"parcel_id\", keep = \"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_assignment) == len(df_parcels)\n",
    "assert set(df_assignment[\"parcel_id\"].unique()) == set(df_parcels[\"parcel_id\"].unique())\n",
    "assert len(df_assignment) == len(df_assignment[\"parcel_id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_parcels = df_parcels.rename(columns = { \"parcel_node\": \"node\" })\n",
    "\n",
    "df_parcels = pd.merge(df_parcels, df_assignment[[\n",
    "    \"parcel_id\", \"depot_id\"]], on = \"parcel_id\", validate = \"one_to_one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output\n",
    "df_parcels.to_file(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lead",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
